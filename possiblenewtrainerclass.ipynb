{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GCNTrainer:\n",
    "    class EarlyStoppingConfig:\n",
    "        def __init__(self, enabled=False, patience=10, threshold=1e-2):\n",
    "            self.enabled = enabled\n",
    "            self.patience = patience\n",
    "            self.threshold = threshold\n",
    "\n",
    "    class CorruptionConfig:\n",
    "        def __init__(self, enabled=False, percentage=0.1):\n",
    "            self.enabled = enabled\n",
    "            self.percentage = percentage\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device='cpu'):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        self.best_model_state_dict = None\n",
    "\n",
    "    def _apply_corruption(self, g_train, corruption_config):\n",
    "        \"\"\"Applica la corruzione alla rete se abilitata.\"\"\"\n",
    "        if corruption_config.enabled:\n",
    "            g_corrupted = corruptNetwork(g_train, corruption_config.percentage)\n",
    "            print(\"The network has been corrupted.\")\n",
    "            return graphToEdgelist(g_corrupted)\n",
    "        return None\n",
    "\n",
    "    def _early_stopping(self, val_auc, best_val_auc, early_stopping_counter, early_stopping_config):\n",
    "        \"\"\"Gestisce la logica per l'early stopping.\"\"\"\n",
    "        if val_auc - best_val_auc > early_stopping_config.threshold:\n",
    "            best_val_auc = val_auc\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_config.enabled and early_stopping_counter >= early_stopping_config.patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            return True, best_val_auc, early_stopping_counter\n",
    "        \n",
    "        return False, best_val_auc, early_stopping_counter\n",
    "\n",
    "    def _perform_negative_sampling(self, edge_index, num_nodes, num_neg_samples):\n",
    "        \"\"\"Esegue il negative sampling.\"\"\"\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=edge_index, num_nodes=num_nodes,\n",
    "            num_neg_samples=num_neg_samples, method='sparse')\n",
    "\n",
    "        return neg_edge_index\n",
    "\n",
    "    def train(self, train_data, g_train, corruption_config=CorruptionConfig(), shuffle=False):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # (Possibly) corrupt the network\n",
    "        train_edge_index_corrupted = self._apply_corruption(g_train, corruption_config)\n",
    "        if train_edge_index_corrupted is None:\n",
    "            train_edge_index_corrupted = train_data.edge_index\n",
    "\n",
    "        # Encoding\n",
    "        z = self.model.encode(train_data.x.to(self.device), train_edge_index_corrupted.to(self.device))\n",
    "\n",
    "        # Negative sampling\n",
    "        neg_edge_index = self._perform_negative_sampling(\n",
    "            edge_index=train_edge_index_corrupted, \n",
    "            num_nodes=train_data.num_nodes,\n",
    "            num_neg_samples=train_data.edge_label_index.size(1)\n",
    "        )\n",
    "\n",
    "        edge_label_index = torch.cat([train_data.edge_label_index, neg_edge_index], dim=-1)\n",
    "        edge_label = torch.cat([train_data.edge_label, \n",
    "                                train_data.edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "\n",
    "        # (Possibly) shuffle the edge_label_index\n",
    "        if shuffle:\n",
    "            shuffle_idx = torch.randperm(edge_label_index.size(1))\n",
    "            edge_label_index = edge_label_index[:, shuffle_idx]\n",
    "            edge_label = edge_label[shuffle_idx]\n",
    "\n",
    "        # Decoding\n",
    "        out = self.model.decode(z, edge_label_index.to(self.device)).view(-1)\n",
    "\n",
    "        # Loss and backpropagation\n",
    "        loss = self.criterion(out, edge_label.to(self.device))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Performance metrics\n",
    "        accuracy = ((out > 0.5).float() == edge_label.to(self.device)).float().mean().item()\n",
    "        auc = roc_auc_score(edge_label.cpu().numpy(), out.cpu().detach().numpy())\n",
    "\n",
    "        return loss.item(), accuracy, auc\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, data, corruption_config=CorruptionConfig(), full_output=False):\n",
    "        self.model.eval()\n",
    "\n",
    "        # (Possibly) corrupt the network\n",
    "        test_edge_index_corrupted = self._apply_corruption(nx.from_edgelist(data.edge_index.t().tolist()), corruption_config)\n",
    "        if test_edge_index_corrupted is None:\n",
    "            test_edge_index_corrupted = data.edge_index\n",
    "\n",
    "        # Encoding and decoding\n",
    "        z = self.model.encode(data.x.to(self.device), test_edge_index_corrupted.to(self.device))\n",
    "        out = self.model.decode(z, data.edge_label_index.to(self.device)).view(-1).sigmoid()\n",
    "\n",
    "        out_cpu = out.cpu().numpy()\n",
    "        label_cpu = data.edge_label.cpu().numpy()\n",
    "\n",
    "        # Performance metrics\n",
    "        accuracy = ((out > 0.5).float().cpu().numpy() == label_cpu).mean()\n",
    "        auc = roc_auc_score(label_cpu, out_cpu)\n",
    "\n",
    "        if full_output:\n",
    "            return accuracy, auc, out_cpu, label_cpu\n",
    "        else:\n",
    "            return accuracy, auc\n",
    "\n",
    "    def train_model(self, train_data, val_data, test_data, \n",
    "                    epochs=100, early_stopping_config=EarlyStoppingConfig(),\n",
    "                    corruption_config=CorruptionConfig(), save_dir='data', run_timestamp=None, save_best_model=False):\n",
    "        \n",
    "        # Get the networkx graphs from the edge lists (used if corrupt=True)\n",
    "        g_train = nx.from_edgelist(train_data.edge_index.t().tolist())\n",
    "        \n",
    "        # Create save directory if it doesn't exist\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize variables\n",
    "        best_val_auc = 0\n",
    "        train_acc_history, train_auc_history, val_acc_history, val_auc_history, loss_history = [np.zeros(epochs) for _ in range(5)]\n",
    "        \n",
    "        early_stopping_counter = 0\n",
    "        total_train_time = 0\n",
    "        total_val_time = 0\n",
    "\n",
    "        # Genera un timestamp unico per l'esecuzione\n",
    "        run_timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        # Training epochs\n",
    "        for epoch in tqdm(range(1, epochs + 1)):\n",
    "            # Training\n",
    "            train_start_time = time.time()\n",
    "            loss, train_accuracy, train_auc = self.train(train_data, g_train, corruption_config=corruption_config)\n",
    "            train_duration = time.time() - train_start_time\n",
    "            total_train_time += train_duration\n",
    "            \n",
    "            # Validation\n",
    "            val_start_time = time.time()\n",
    "            val_acc, val_auc = self.test(val_data, corruption_config=corruption_config)\n",
    "            val_duration = time.time() - val_start_time\n",
    "            total_val_time += val_duration\n",
    "            \n",
    "            # Save metrics\n",
    "            loss_history[epoch - 1] = loss\n",
    "            train_acc_history[epoch - 1] = train_accuracy\n",
    "            train_auc_history[epoch - 1] = train_auc\n",
    "            val_acc_history[epoch - 1] = val_acc\n",
    "            val_auc_history[epoch - 1] = val_auc\n",
    "\n",
    "            # Evaluate best model\n",
    "            stop, best_val_auc, early_stopping_counter = self._early_stopping(val_auc, best_val_auc, early_stopping_counter, early_stopping_config)\n",
    "            if stop:\n",
    "                print(f\"Early stopping at epoch {epoch}.\")\n",
    "                return (train_acc_history[:epoch], train_auc_history[:epoch], \n",
    "                        val_acc_history[:epoch], val_auc_history[:epoch], \n",
    "                        loss_history[:epoch], run_timestamp)\n",
    "            \n",
    "            if save_best_model:\n",
    "                self.best_model_state_dict = self.model.state_dict()  # Salva il miglior stato del modello\n",
    "\n",
    "        print(f\"Total training time: {total_train_time:.4f} seconds.\")\n",
    "        print(f\"Total validation time: {total_val_time:.4f} seconds.\")\n",
    "\n",
    "        return train_acc_history[:epoch], train_auc_history[:epoch], val_acc_history[:epoch], val_auc_history[:epoch], loss_history[:epoch], run_timestamp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
